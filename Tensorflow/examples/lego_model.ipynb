{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9cfa63b",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Mohamed-Mehira/AI-computer-vision/blob/master/Tensorflow/examples/lego_model.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65fd031",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import random\n",
    "import shutil\n",
    "import math\n",
    "import cv2\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sn\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bebac90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.keras.backend.clear_session()\n",
    "from importlib import reload\n",
    "reload(keras.models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcb6f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading class names\n",
    "\n",
    "BASE_dir = '../Datasets/lego/'\n",
    "\n",
    "class_names_df = pd.read_csv(BASE_dir + 'metadata.csv', encoding='ISO-8859-1')\n",
    "class_names = list(class_names_df['minifigure_name'])\n",
    "\n",
    "tf.random.set_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fa9c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing our data\n",
    "\n",
    "def change_path(path):\n",
    "    path = BASE_dir + path\n",
    "    return path\n",
    "\n",
    "dataset_df = pd.read_csv(BASE_dir + 'index.csv', encoding='ISO-8859-1')\n",
    "test_data = pd.read_csv(BASE_dir + 'test.csv', encoding='ISO-8859-1')\n",
    "\n",
    "dataset_df.path = dataset_df.path.apply(change_path)\n",
    "test_data.path = test_data.path.apply(change_path)\n",
    "\n",
    "print(dataset_df.shape)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61734a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting our data into training and validation\n",
    "\n",
    "train_data = pd.DataFrame()\n",
    "val_data = pd.DataFrame()\n",
    "val_percentage = 0.3\n",
    "\n",
    "grouped_df = dataset_df.groupby('class_id')\n",
    "for group_name, group_data in grouped_df:\n",
    "    val_samples = group_data.sample(frac=val_percentage, random_state=42)\n",
    "    val_data = pd.concat([val_data, val_samples])\n",
    "    \n",
    "    train_samples = group_data.drop(val_samples.index)\n",
    "    train_data = pd.concat([train_data, train_samples])\n",
    "\n",
    "train_data = train_data.sample(frac=1, random_state=42)\n",
    "val_data = val_data.sample(frac=1, random_state=42)\n",
    "\n",
    "train_data.reset_index(drop=True, inplace=True)\n",
    "val_data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(train_data.shape)\n",
    "print(val_data.shape)\n",
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fba5dc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# splitting our data into images and labels\n",
    "\n",
    "train_imgs = []\n",
    "val_imgs = []\n",
    "test_imgs = []\n",
    "\n",
    "train_img_paths = train_data.path\n",
    "val_img_paths = val_data.path\n",
    "test_img_paths = test_data.path\n",
    "\n",
    "for train_img_path in train_img_paths:\n",
    "    train_img = mpimg.imread(train_img_path)\n",
    "    train_img = cv2.resize(train_img, (256, 256))\n",
    "    train_imgs.append(train_img)\n",
    "    \n",
    "for val_img_path in val_img_paths:\n",
    "    val_img = mpimg.imread(val_img_path)\n",
    "    val_img = cv2.resize(val_img, (256, 256))\n",
    "    val_imgs.append(val_img)\n",
    "    \n",
    "for test_img_path in test_img_paths:\n",
    "    test_img = mpimg.imread(test_img_path)\n",
    "    test_img = cv2.resize(test_img, (256, 256))\n",
    "    test_imgs.append(test_img)\n",
    "\n",
    "train_imgs = np.array(train_imgs) / 255\n",
    "val_imgs = np.array(val_imgs) / 255\n",
    "test_imgs = np.array(test_imgs) / 255\n",
    "\n",
    "train_labels = train_data.class_id.values\n",
    "val_labels = val_data.class_id.values\n",
    "test_labels = test_data.class_id.values\n",
    "\n",
    "print(train_imgs.shape)\n",
    "print(val_imgs.shape)\n",
    "print(test_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1767830",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(images, labels, n=9, pred_labels=None):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    for i in range(n):\n",
    "        x = int(math.sqrt(n))\n",
    "        plt.subplot(x,x,i+1)\n",
    "        plt.xticks([])\n",
    "        plt.yticks([])\n",
    "        plt.grid(False)\n",
    "        image = images[i]\n",
    "        plt.imshow(image, cmap=plt.cm.binary)\n",
    "        label = class_names[labels[i]-1]\n",
    "        if pred_labels is not None:\n",
    "            label += \"/ Pred:\" + class_names[pred_labels[i]-1]\n",
    "        plt.xlabel(label)\n",
    "    plt.show()\n",
    "    \n",
    "show(train_imgs[20:60], train_labels[20:60], n=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa599255",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using transfer learning\n",
    "\n",
    "vgg_model = tf.keras.applications.vgg16.VGG16()\n",
    "print(type(vgg_model))\n",
    "# vgg_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "697910ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.models.Sequential()\n",
    "for layer in vgg_model.layers[0:-1]:\n",
    "    layer.trainable = False\n",
    "    model.add(layer)\n",
    "    \n",
    "model.summary()\n",
    "\n",
    "model.add(layers.Dense(38))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fea7c9d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# using my own model\n",
    "\n",
    "# model = keras.models.Sequential()\n",
    "# model.add(layers.Conv2D(32, (3,3), strides=(1,1), padding=\"valid\", activation='relu', input_shape=(256, 256, 3)))\n",
    "# model.add(layers.MaxPool2D((2,2)))\n",
    "# model.add(layers.Conv2D(64, 3, activation='relu'))\n",
    "# model.add(layers.MaxPool2D((2,2)))\n",
    "# model.add(layers.Flatten())\n",
    "# model.add(layers.Dense(128, activation='relu'))\n",
    "# model.add(layers.Dense(64, activation='relu'))\n",
    "# model.add(layers.Dense(38))\n",
    "# print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "390ec232",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "optim = keras.optimizers.Adam(learning_rate=0.001)\n",
    "metrics = ['accuracy']\n",
    "\n",
    "model.compile(optimizer=optim, loss=loss, metrics=metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8edd7a9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# callbacks\n",
    "# early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=5, verbose=2)\n",
    "\n",
    "history = model.fit(train_imgs, train_labels, validation_data=(val_imgs, val_labels), batch_size=12, epochs=30, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5129ec19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('lego-classifier_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a41afbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['loss'], label='train loss')\n",
    "plt.plot(history.history['val_loss'], label='valid loss')\n",
    "plt.grid()\n",
    "plt.legend(fontsize=15)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['accuracy'], label='train accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='validation accuracy')\n",
    "plt.grid()\n",
    "plt.legend(fontsize=15);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52887813",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_batches, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40202fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
